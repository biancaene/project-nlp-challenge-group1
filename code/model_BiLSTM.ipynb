{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5eb6ac2",
   "metadata": {},
   "source": [
    "# Deep Learning Model: BiLSTM + Embeddings (Fake News Classification)\n",
    "\n",
    "This notebook trains a Bidirectional LSTM (BiLSTM) model using learned word embeddings for fake news classification.\n",
    "We compare it to a simpler embedding baseline to see whether sequence modeling (word order) helps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442526c",
   "metadata": {},
   "source": [
    "## 1) Environment & Reproducibility\n",
    "\n",
    "- Forcing CPU mode to avoid CUDA/TensorFlow kernel crashes in WSL.\n",
    "- This notebook is still run using the `tf-gpu` kernel, but TensorFlow will ignore GPU devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b8118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879e750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 05:43:07.398105: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-05 05:43:08.068231: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-05 05:43:09.757316: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d03135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "GPUs visible to TF: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-05 05:43:14.531308: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "#Device Check\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPUs visible to TF:\", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bc950",
   "metadata": {},
   "source": [
    "## 2) Load Dataset\n",
    "\n",
    "Loads the training dataset and identifies:\n",
    "- the text column used as input\n",
    "- the label column used as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39aa4705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (34152, 2)\n",
      "test : (9984, 1)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = \"../data/training_data_lowercase.csv\"\n",
    "TEST_PATH  = \"../data/testing_data_lowercase_nolabels.csv\"\n",
    "\n",
    "data = pd.read_csv(TRAIN_PATH, sep=\"\\t\", header=None, names=[\"label\", \"text\"])\n",
    "data_out = pd.read_csv(TEST_PATH, sep=\"\\t\", header=None, names=[\"text\"])\n",
    "\n",
    "print(\"train:\", data.shape)\n",
    "print(\"test :\", data_out.shape)\n",
    "data.head()\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f1887a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (34152, 2)\n",
      "Missing text: 0\n",
      "Missing labels: 0\n",
      "\n",
      "Label distribution:\n",
      " label\n",
      "0    17572\n",
      "1    16580\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", data.shape)\n",
    "print(\"Missing text:\", data[TEXT_COL].isna().sum())\n",
    "print(\"Missing labels:\", data[LABEL_COL].isna().sum())\n",
    "print(\"\\nLabel distribution:\\n\", data[LABEL_COL].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d6840",
   "metadata": {},
   "source": [
    "## 3) Train/Validation Split + Label Encoding\n",
    "\n",
    "- Encodes labels into integers for `sparse_categorical_crossentropy`.\n",
    "- Splits once and reuses the same split for all deep models in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "821c334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 27321 | Val size: 6831\n",
      "Classes: [np.int64(0), np.int64(1)]\n"
     ]
    }
   ],
   "source": [
    "# Train/Validation Split + Label Encoding\n",
    "\n",
    "X_text = data[TEXT_COL].astype(str)\n",
    "y_label = data[LABEL_COL]\n",
    "\n",
    "# label mappings\n",
    "class_labels = sorted(y_label.unique())\n",
    "label_to_id = {label: idx for idx, label in enumerate(class_labels)}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "# Convert labels to integers (for sparse_categorical_crossentropy)\n",
    "y_id = y_label.map(label_to_id).astype(\"int32\").to_numpy()\n",
    "\n",
    "# Split once (reuse this split for all models in this notebook)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_text, y_id,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_id\n",
    ")\n",
    "\n",
    "# dtype-safe arrays for Keras (avoid pandas object dtype issues)\n",
    "X_train_np = X_train.astype(str).to_numpy()\n",
    "X_val_np   = X_val.astype(str).to_numpy()\n",
    "\n",
    "print(\"Train size:\", len(X_train_np), \"| Val size:\", len(X_val_np))\n",
    "print(\"Classes:\", class_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce1344",
   "metadata": {},
   "source": [
    "## 4) Text Vectorization\n",
    "\n",
    "Converts raw text into integer token sequences.\n",
    "IMPORTANT: `.adapt()` is fit ONLY on training text to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 20000\n",
    "seq_len = 250\n",
    "\n",
    "vectorize = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=seq_len\n",
    ")\n",
    "vectorize.adapt(X_train_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b7af0",
   "metadata": {},
   "source": [
    "## 5) Baseline: Simple Neural Network (Embeddings + Global Average Pooling)\n",
    "\n",
    "This baseline ignores word order and pools embeddings across the sequence.\n",
    "We compare against BiLSTM to see if sequence modeling improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd4f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,290</span> (4.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,284,290\u001b[0m (4.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,290</span> (4.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,284,290\u001b[0m (4.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(class_labels)\n",
    "\n",
    "simple_nn = keras.Sequential([\n",
    "    keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize,\n",
    "    layers.Embedding(max_tokens, 64),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "simple_nn.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "simple_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d28f2839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5326 - loss: 0.6891 - val_accuracy: 0.6187 - val_loss: 0.6597\n",
      "Epoch 2/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.5293 - val_accuracy: 0.5942 - val_loss: 0.6685\n",
      "Epoch 3/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8757 - loss: 0.2948 - val_accuracy: 0.8691 - val_loss: 0.2867\n",
      "Epoch 4/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8980 - loss: 0.2430 - val_accuracy: 0.9319 - val_loss: 0.1861\n",
      "Epoch 5/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9068 - loss: 0.2245 - val_accuracy: 0.9392 - val_loss: 0.1614\n",
      "Epoch 6/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9194 - loss: 0.1972 - val_accuracy: 0.9385 - val_loss: 0.1520\n",
      "Epoch 7/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9320 - loss: 0.1706 - val_accuracy: 0.8842 - val_loss: 0.2615\n",
      "Epoch 8/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.1867 - val_accuracy: 0.8377 - val_loss: 0.3373\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "history_simple = simple_nn.fit(\n",
    "    X_train_np, y_train,\n",
    "    validation_data=(X_val_np, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d10db422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple NN Accuracy: 0.9385\n",
      "Simple NN F1 (weighted): 0.9385\n"
     ]
    }
   ],
   "source": [
    "val_prob_simple = simple_nn.predict(X_val_np, verbose=0)\n",
    "val_pred_id_simple = val_prob_simple.argmax(axis=1)\n",
    "\n",
    "y_val_label = pd.Series(y_val).map(id_to_label)\n",
    "val_pred_label_simple = pd.Series(val_pred_id_simple).map(id_to_label)\n",
    "\n",
    "simple_acc = accuracy_score(y_val_label, val_pred_label_simple)\n",
    "simple_f1  = f1_score(y_val_label, val_pred_label_simple, average=\"weighted\")\n",
    "\n",
    "print(\"Simple NN Accuracy:\", round(simple_acc, 4))\n",
    "print(\"Simple NN F1 (weighted):\", round(simple_f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96fcb1e",
   "metadata": {},
   "source": [
    "## 6) Main Model: BiLSTM + Embeddings\n",
    "\n",
    "BiLSTM reads the sequence in both directions (left→right and right→left),\n",
    "which can capture phrasing and context that a pooled model may miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe1e6424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,354,434</span> (5.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,354,434\u001b[0m (5.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,354,434</span> (5.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,354,434\u001b[0m (5.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bilstm_model = keras.Sequential([\n",
    "    keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize,\n",
    "    layers.Embedding(max_tokens, 64),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "bilstm_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "bilstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "895b9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 81ms/step - accuracy: 0.9209 - loss: 0.1839 - val_accuracy: 0.9707 - val_loss: 0.0825\n",
      "Epoch 2/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 80ms/step - accuracy: 0.9822 - loss: 0.0499 - val_accuracy: 0.9640 - val_loss: 0.0995\n",
      "Epoch 3/10\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 81ms/step - accuracy: 0.9940 - loss: 0.0186 - val_accuracy: 0.9612 - val_loss: 0.1194\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "history_bilstm = bilstm_model.fit(\n",
    "    X_train_np, y_train,\n",
    "    validation_data=(X_val_np, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7995e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM Accuracy: 0.9707\n",
      "BiLSTM F1 (weighted): 0.9707\n"
     ]
    }
   ],
   "source": [
    "val_prob_bilstm = bilstm_model.predict(X_val_np, verbose=0)\n",
    "val_pred_id_bilstm = val_prob_bilstm.argmax(axis=1)\n",
    "\n",
    "val_pred_label_bilstm = pd.Series(val_pred_id_bilstm).map(id_to_label)\n",
    "\n",
    "bilstm_acc = accuracy_score(y_val_label, val_pred_label_bilstm)\n",
    "bilstm_f1  = f1_score(y_val_label, val_pred_label_bilstm, average=\"weighted\")\n",
    "\n",
    "print(\"BiLSTM Accuracy:\", round(bilstm_acc, 4))\n",
    "print(\"BiLSTM F1 (weighted):\", round(bilstm_f1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995784a",
   "metadata": {},
   "source": [
    "## 7) Results Summary\n",
    "\n",
    "Side-by-side comparison of:\n",
    "- Simple Embedding Baseline (orderless)\n",
    "- BiLSTM (sequence-aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09b6efde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiLSTM (Emb + BiLSTM)</td>\n",
       "      <td>0.970722</td>\n",
       "      <td>0.970723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple NN (Emb + Pool)</td>\n",
       "      <td>0.938516</td>\n",
       "      <td>0.938521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  accuracy  f1_weighted\n",
       "1   BiLSTM (Emb + BiLSTM)  0.970722     0.970723\n",
       "0  Simple NN (Emb + Pool)  0.938516     0.938521"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame([\n",
    "    {\"model\": \"Simple NN (Emb + Pool)\", \"accuracy\": simple_acc, \"f1_weighted\": simple_f1},\n",
    "    {\"model\": \"BiLSTM (Emb + BiLSTM)\", \"accuracy\": bilstm_acc, \"f1_weighted\": bilstm_f1},\n",
    "]).sort_values(\"f1_weighted\", ascending=False)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69414e",
   "metadata": {},
   "source": [
    "## 8) Notes for Presentation\n",
    "\n",
    "- Baseline pools embeddings (ignores word order).\n",
    "- BiLSTM reads text in both directions, capturing context/phrasing.\n",
    "- Report Weighted F1 as the main metric.\n",
    "- If BiLSTM improves, it suggests sequence/context matters.\n",
    "- If not, classic TF-IDF + linear models may still be best for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01e1d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../outputs/pred_bilstm.csv\n"
     ]
    }
   ],
   "source": [
    "test_text_np = data_out[TEXT_COL].astype(str).to_numpy()\n",
    "\n",
    "test_prob = bilstm_model.predict(test_text_np, verbose=0)\n",
    "test_pred_id = test_prob.argmax(axis=1)\n",
    "test_pred_label = pd.Series(test_pred_id).map(id_to_label)\n",
    "\n",
    "out_path = \"../outputs/pred_bilstm.csv\"\n",
    "pd.DataFrame({\"prediction\": test_pred_label}).to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf609c4",
   "metadata": {},
   "source": [
    "## Metrics dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d653e2",
   "metadata": {},
   "source": [
    "### A) Simple NN baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "158d08b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple NN (Emb + Pool) ===\n",
      "Accuracy: 0.9385\n",
      "Precision (weighted): 0.9398\n",
      "Recall (weighted): 0.9385\n",
      "F1 (weighted): 0.9385\n",
      "Val loss: 0.3373\n",
      "Epochs run: 8\n",
      "Batch size: 64\n",
      "Early stopping: yes (patience=2)\n",
      "Optimizer: Adam (default lr)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "simple_precision = precision_score(y_val_label, val_pred_label_simple, average=\"weighted\", zero_division=0)\n",
    "simple_recall    = recall_score(y_val_label, val_pred_label_simple, average=\"weighted\", zero_division=0)\n",
    "\n",
    "# Pull final val_loss from history (works even with early stopping)\n",
    "simple_val_loss = float(history_simple.history[\"val_loss\"][-1])\n",
    "\n",
    "print(\"=== Simple NN (Emb + Pool) ===\")\n",
    "print(\"Accuracy:\", round(simple_acc, 4))\n",
    "print(\"Precision (weighted):\", round(simple_precision, 4))\n",
    "print(\"Recall (weighted):\", round(simple_recall, 4))\n",
    "print(\"F1 (weighted):\", round(simple_f1, 4))\n",
    "print(\"Val loss:\", round(simple_val_loss, 4))\n",
    "print(\"Epochs run:\", len(history_simple.history[\"loss\"]))\n",
    "print(\"Batch size:\", 64)\n",
    "print(\"Early stopping:\", \"yes (patience=2)\")\n",
    "print(\"Optimizer:\", \"Adam (default lr)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8928c",
   "metadata": {},
   "source": [
    "### B) BiLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "733c25cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BiLSTM (Emb + BiLSTM) ===\n",
      "Accuracy: 0.9707\n",
      "Precision (weighted): 0.9707\n",
      "Recall (weighted): 0.9707\n",
      "F1 (weighted): 0.9707\n",
      "Val loss: 0.1194\n",
      "Epochs run: 3\n",
      "Batch size: 64\n",
      "Early stopping: yes (patience=2)\n",
      "Optimizer: Adam (default lr)\n"
     ]
    }
   ],
   "source": [
    "bilstm_precision = precision_score(y_val_label, val_pred_label_bilstm, average=\"weighted\", zero_division=0)\n",
    "bilstm_recall    = recall_score(y_val_label, val_pred_label_bilstm, average=\"weighted\", zero_division=0)\n",
    "\n",
    "bilstm_val_loss = float(history_bilstm.history[\"val_loss\"][-1])\n",
    "\n",
    "print(\"\\n=== BiLSTM (Emb + BiLSTM) ===\")\n",
    "print(\"Accuracy:\", round(bilstm_acc, 4))\n",
    "print(\"Precision (weighted):\", round(bilstm_precision, 4))\n",
    "print(\"Recall (weighted):\", round(bilstm_recall, 4))\n",
    "print(\"F1 (weighted):\", round(bilstm_f1, 4))\n",
    "print(\"Val loss:\", round(bilstm_val_loss, 4))\n",
    "print(\"Epochs run:\", len(history_bilstm.history[\"loss\"]))\n",
    "print(\"Batch size:\", 64)\n",
    "print(\"Early stopping:\", \"yes (patience=2)\")\n",
    "print(\"Optimizer:\", \"Adam (default lr)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
